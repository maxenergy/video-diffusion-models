{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Video diffusion models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:14.138442Z","iopub.status.busy":"2022-12-17T18:30:14.137828Z","iopub.status.idle":"2022-12-17T18:30:14.156193Z","shell.execute_reply":"2022-12-17T18:30:14.155406Z","shell.execute_reply.started":"2022-12-17T18:30:14.138343Z"},"trusted":true},"outputs":[],"source":["# Here wget old checkpoint\n","# !wget ..."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:14.173709Z","iopub.status.busy":"2022-12-17T18:30:14.173457Z","iopub.status.idle":"2022-12-17T18:30:14.182066Z","shell.execute_reply":"2022-12-17T18:30:14.181172Z","shell.execute_reply.started":"2022-12-17T18:30:14.173684Z"},"trusted":true},"outputs":[],"source":["# Params\n","image_size = 256\n","frames = 5\n","download_batch_size = 128\n","download_workers = 20\n","\n","dataset_size = 125782\n","\n","# If there is a checkpoint these changes automatically at runtime\n","epoch = 1\n","train_unet = 1\n","current_step = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:14.221922Z","iopub.status.busy":"2022-12-17T18:30:14.221218Z","iopub.status.idle":"2022-12-17T18:30:14.227467Z","shell.execute_reply":"2022-12-17T18:30:14.226324Z","shell.execute_reply.started":"2022-12-17T18:30:14.221883Z"},"trusted":true},"outputs":[],"source":["import time\n","import os\n","start_time = time.time()\n","\n","# Clean tmp files\n","for file in os.listdir(\"./\"):\n","    if file.endswith('.gif'):\n","        os.remove(file)"]},{"cell_type":"markdown","metadata":{},"source":["## Install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:14.295362Z","iopub.status.busy":"2022-12-17T18:30:14.293161Z","iopub.status.idle":"2022-12-17T18:30:28.008245Z","shell.execute_reply":"2022-12-17T18:30:28.007062Z","shell.execute_reply.started":"2022-12-17T18:30:14.295333Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["!pip install imagen_pytorch==1.16.5"]},{"cell_type":"markdown","metadata":{},"source":["## Utility functions to resize and crop GIFs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:28.011698Z","iopub.status.busy":"2022-12-17T18:30:28.011299Z","iopub.status.idle":"2022-12-17T18:30:29.882784Z","shell.execute_reply":"2022-12-17T18:30:29.881816Z","shell.execute_reply.started":"2022-12-17T18:30:28.011659Z"},"tags":[],"trusted":true},"outputs":[],"source":["# GIF pre-processing\n","\n","import numpy as np\n","from torchvision import transforms as T\n","from math import floor, fabs\n","from PIL import Image, ImageSequence\n","\n","\n","CHANNELS_TO_MODE = {\n","    1 : 'L',\n","    3 : 'RGB',\n","    4 : 'RGBA'\n","}\n","\n","def center_crop(img, new_width, new_height): \n","    width = img.size[0]\n","    height = img.size[1]\n","    left = int(np.ceil((width - new_width) / 2))\n","    right = width - int(np.floor((width - new_width) / 2))\n","    top = int(np.ceil((height - new_height) / 2))\n","    bottom = height - int(np.floor((height - new_height) / 2))\n","    return img.crop((left, top, right, bottom))\n","\n","def resize_crop_img(img, width, height):\n","    # width < height\n","    if( img.size[0] < img.size[1]):\n","        wpercent = (width/float(img.size[0]))\n","        hsize = int((float(img.size[1])*float(wpercent)))\n","        img = img.resize((width, hsize), Image.Resampling.LANCZOS)\n","    else: # width >= height\n","        hpercent = (height/float(img.size[1]))\n","        wsize = int((float(img.size[0])*float(hpercent)))\n","        img = img.resize((wsize, height), Image.Resampling.LANCZOS)\n","    img = center_crop(img, width, height)\n","    # print(img.size[0])\n","    # print(img.size[1])\n","    return img\n","\n","def transform_gif(img, new_width, new_height, frames, channels = 3):\n","    assert channels in CHANNELS_TO_MODE, f'channels {channels} invalid'\n","    mode = CHANNELS_TO_MODE[channels]\n","    gif_frames = img.n_frames\n","    for i in range(0, frames):\n","        img.seek(i % gif_frames)\n","        img_out = resize_crop_img(img, new_width, new_height)\n","        yield img_out.convert(mode)\n","        \n","# tensor of shape (channels, frames, height, width) -> gif\n","def video_tensor_to_gif(tensor, path, fps = 10, loop = 0, optimize = True):\n","    print(\"Converting video tensors to GIF\")\n","    images = map(T.ToPILImage(), tensor.unbind(dim = 1))\n","    first_img, *rest_imgs = images\n","    print(1000/fps)\n","    first_img.save(path, save_all = True, append_images = rest_imgs, duration = int(1000/fps), loop = loop, optimize = optimize)\n","    print(\"Gif saved\")\n","    return images\n","\n","# gif -> (channels, frame, height, width) tensor\n","def gif_to_tensor(path, width = 256, height = 256, frames = 32, channels = 3, transform = T.ToTensor()):\n","    print(\"Converting GIF to video tensors\")\n","    img = Image.open(path)\n","    imgs = transform_gif(img, new_width = width, new_height = height, frames = frames, channels = channels)\n","    tensors = tuple(map(transform, imgs))\n","    return torch.stack(tensors, dim = 1)"]},{"cell_type":"markdown","metadata":{},"source":["## Utility functions to download dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:29.884919Z","iopub.status.busy":"2022-12-17T18:30:29.884258Z","iopub.status.idle":"2022-12-17T18:30:29.905598Z","shell.execute_reply":"2022-12-17T18:30:29.904455Z","shell.execute_reply.started":"2022-12-17T18:30:29.884882Z"},"tags":[],"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import shutil\n","import urllib\n","\n","from concurrent.futures import ThreadPoolExecutor, wait\n","import time\n","import threading\n","\n","train_url = \"https://raw.githubusercontent.com/raingo/TGIF-Release/master/data/tgif-v1.0.tsv\"\n","train_data = \"./train_data.tvs\"\n","\n","current_step = 0\n","texts = []\n","list_videos = []\n","\n","\n","def download_url(url, root, filename=None):\n","    \"\"\"Download a file from a url and place it in root.\n","    Args:\n","        url (str): URL to download file from\n","        root (str): Directory to place downloaded file in\n","        filename (str, optional): Name to save the file under. If None, use the basename of the URL\n","    \"\"\"\n","    root = os.path.expanduser(root)\n","    if not filename:\n","        filename = os.path.basename(url)\n","    fpath = os.path.join(root, filename)\n","\n","    os.makedirs(root, exist_ok=True)\n","\n","    try:\n","        #print('Downloading ' + url + ' to ' + fpath)\n","        urllib.request.urlretrieve(url, fpath)\n","    except (urllib.error.URLError, IOError) as e:\n","        if url[:5] == 'https':\n","            url = url.replace('https:', 'http:')\n","            print('Failed download. Trying https -> http instead.'\n","                    ' Downloading ' + url + ' to ' + fpath)\n","            urllib.request.urlretrieve(url, fpath)\n","\n","def get_videos(index_start, index_end):\n","    global texts\n","    global list_videos\n","    \n","    texts = []\n","    list_videos = []\n","\n","    with open(\"train_data.tvs\") as fp:\n","        for i, line in enumerate(fp):\n","            if i >= index_start and i< index_end :\n","                try:\n","                    file_img, file_text = line.split(\"\\t\")\n","                    print(f\"Downloading image {i}\")\n","                    download_url(file_img, \"./\", \"download.gif\")\n","                    tensor = gif_to_tensor('download.gif', width = image_size, height = image_size, frames = frames)\n","                    list_videos.append(tensor)\n","                    file_text = file_text[:-1] # Remove \\n\n","                    texts.append(file_text)\n","                    os.remove('download.gif')\n","                except Exception as ex:\n","                    print(ex)\n","                    pass\n","            elif i > index_end:\n","                break\n","\n","lock = threading.Lock()\n","executor = ThreadPoolExecutor(max_workers=download_workers)\n","\n","def download_process_parallel(index, file_img, file_text):\n","    try:\n","        print(f\"Downloading image {index}\")\n","        download_url(file_img, \"./\", f\"{index}.gif\")\n","        tensor = gif_to_tensor(f\"{index}.gif\", width = image_size, height = image_size, frames = frames)\n","        file_text = file_text[:-1] # Remove \\n\n","        with lock:\n","            list_videos.append(tensor)\n","            texts.append(file_text)\n","        os.remove(f\"{index}.gif\")\n","    except Exception as ex:\n","        print(ex)\n","        pass\n","    \n","def get_videos_parallel(index_start, index_end):\n","    global texts\n","    global list_videos\n","    \n","    texts = []\n","    list_videos = []\n","\n","    with open(\"train_data.tvs\") as fp:\n","        futures = []\n","        for i, line in enumerate(fp):\n","            if i >= index_start and i< index_end :\n","                file_img, file_text = line.split(\"\\t\")\n","                future = executor.submit(download_process_parallel, i, file_img, file_text)\n","                futures.append(future)\n","            elif i > index_end:\n","                break\n","        wait(futures)\n","                \n","def get_next_videos():\n","    global current_step\n","    get_videos_parallel(current_step, current_step + download_batch_size)\n","    current_step += len(texts)\n","\n","# Download train data file\n","if not os.path.exists(train_data):\n","    download_url(train_url, \"./\", train_data)"]},{"cell_type":"markdown","metadata":{},"source":["## Utility functions to save and load checkpoints"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:29.909608Z","iopub.status.busy":"2022-12-17T18:30:29.909213Z","iopub.status.idle":"2022-12-17T18:30:32.858709Z","shell.execute_reply":"2022-12-17T18:30:32.857664Z","shell.execute_reply.started":"2022-12-17T18:30:29.909564Z"},"tags":[],"trusted":true},"outputs":[],"source":["import shutil\n","import torch\n","import time\n","import gc\n","import os\n","from imagen_pytorch import ImagenTrainer\n","from imagen_pytorch.data import Dataset\n","\n","checkpoints_path = \"./\"\n","checkpoint_path = \"\"\n","\n","def save_checkpoint(trainer: ImagenTrainer):\n","    global checkpoint_path\n","    print(\"Saving checkpoint\")\n","    current_time = int(time.time())\n","    if os.path.exists(checkpoint_path):\n","        os.remove(checkpoint_path)\n","    checkpoint_path = os.path.join(checkpoints_path, f\"checkpoint-unet_{train_unet}-epoch_{epoch}-step_{current_step}-{current_time}.pt\")\n","    gc.collect()\n","    trainer.save(checkpoint_path)\n","\n","def update_config(checkpoint):\n","    global epoch\n","    global train_unet\n","    global current_step\n","    splitted = (checkpoint.replace(\".pt\", \"\").split(\"checkpoint-\")[1]).split(\"-\")\n","    print(splitted)\n","    train_unet = int(splitted[0].replace(\"unet_\", \"\"))\n","    epoch = int(splitted[1].replace(\"epoch_\", \"\"))\n","    current_step = int(splitted[2].replace(\"step_\", \"\"))\n","    print(\"Loaded configuration\")\n","    print(f\"Step: {current_step}\")\n","    print(f\"Epoch: {epoch}\")\n","    print(f\"Unet: {train_unet}\")\n","    if current_step >= dataset_size:\n","#     if current_step >= 1:\n","        if train_unet == 2:\n","            print(\"End of training Unet 2 -> New epoch\")\n","            train_unet = 1\n","            epoch += 1\n","        else:\n","            print(\"End of training Unet 1\")\n","            train_unet = 2\n","        current_step = 0\n","        print(\"New configuration\")\n","        print(f\"Step: {current_step}\")\n","        print(f\"Epoch: {epoch}\")\n","        print(f\"Unet: {train_unet}\")\n","        \n","def load_checkpoint(trainer: ImagenTrainer):\n","    global checkpoint_path\n","    print(\"Loading checkpoint\")\n","    timestamp = -1\n","    for file in os.listdir(checkpoints_path):\n","        if file.endswith('.pt'):\n","            new_timestamp = int((file.split(\"-\")[4]).replace(\".pt\", \"\"))\n","            if new_timestamp > timestamp:\n","                checkpoint_path = os.path.join(checkpoints_path, file)\n","                timestamp = new_timestamp        \n","    if not os.path.exists(checkpoint_path):\n","        print(\"No checkpoint found -> starting from scratch\")\n","        return None\n","    gc.collect()\n","    trainer.load(checkpoint_path)\n","    update_config(checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:32.860707Z","iopub.status.busy":"2022-12-17T18:30:32.860005Z","iopub.status.idle":"2022-12-17T18:30:40.217898Z","shell.execute_reply":"2022-12-17T18:30:40.216837Z","shell.execute_reply.started":"2022-12-17T18:30:32.860676Z"},"tags":[],"trusted":true},"outputs":[],"source":["from imagen_pytorch import Unet3D, ElucidatedImagen, ImagenTrainer\n","\n","unet1 = Unet3D(\n","    dim = 64,\n","    cond_dim = 512,\n","    dim_mults = (1, 2, 4, 8),\n","    num_resnet_blocks = 3,\n","    layer_attns = (False, True, True, True),\n","    layer_cross_attns = (False, True, True, True)\n",")\n","\n","unet2 = Unet3D(\n","    dim = 64,\n","    cond_dim = 512,\n","    dim_mults = (1, 2, 4, 8),\n","    num_resnet_blocks = (2, 4, 8, 8),\n","    layer_attns = (False, False, False, True),\n","    layer_cross_attns = (False, False, False, True)\n",")\n","\n","imagen = ElucidatedImagen(\n","    unets = (unet1, unet2),\n","    image_sizes = (32, 256),\n","    random_crop_sizes = (None, 16),\n","    num_sample_steps = 64,\n","    cond_drop_prob = 0.1,                       # gives the probability of dropout for classifier-free guidance.\n","    sigma_min = 0.002,                          # min noise level\n","    sigma_max = (80, 160),                      # max noise level, double the max noise level for upsampler\n","    sigma_data = 0.5,                           # standard deviation of data distribution\n","    rho = 7,                                    # controls the sampling schedule\n","    P_mean = -1.2,                              # mean of log-normal distribution from which noise is drawn for training\n","    P_std = 1.2,                                # standard deviation of log-normal distribution from which noise is drawn for training\n","    S_churn = 80,                               # parameters for stochastic sampling - depends on dataset, Table 5 in apper\n","    S_tmin = 0.05,\n","    S_tmax = 50,\n","    S_noise = 1.003,\n",").cuda()\n","\n","trainer = ImagenTrainer(imagen)"]},{"cell_type":"markdown","metadata":{},"source":["## Train Unet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:30:40.225438Z","iopub.status.busy":"2022-12-17T18:30:40.222941Z","iopub.status.idle":"2022-12-17T18:33:03.793199Z","shell.execute_reply":"2022-12-17T18:33:03.792064Z","shell.execute_reply.started":"2022-12-17T18:30:40.225394Z"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"source":["# Train \n","load_checkpoint(trainer)\n","# counter = 0\n","while True:\n","    # if execution time is more than 11h40m stops\n","    if time.time() - start_time > 42000:\n","        break\n","    get_next_videos()\n","    # if there are no more videos stops\n","    if len(texts) == 0:\n","        break\n","    print(\"Generating tensor from videos\")\n","    videos = torch.stack(list_videos, dim = 0).cuda()\n","    print(f\"Training Unet {train_unet}\")\n","    trainer(videos, texts = texts, unet_number = train_unet, max_batch_size = 16)\n","    trainer.update(unet_number = train_unet)\n","    del videos\n","    \n","#     if counter == 5:\n","#         break\n","#     counter +=1\n","save_checkpoint(trainer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:33:03.801108Z","iopub.status.busy":"2022-12-17T18:33:03.798736Z","iopub.status.idle":"2022-12-17T18:33:03.810774Z","shell.execute_reply":"2022-12-17T18:33:03.806758Z","shell.execute_reply.started":"2022-12-17T18:33:03.801046Z"},"trusted":true},"outputs":[],"source":["# texts_sample = ['black']\n","# load_checkpoint(trainer)\n","# videos_out = trainer.sample(texts = texts_sample, video_frames = 24)\n","# print(videos_out.shape)\n","# video_tensor_to_gif(videos_out[0], f'out.gif', fps = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:33:03.818747Z","iopub.status.busy":"2022-12-17T18:33:03.812982Z","iopub.status.idle":"2022-12-17T18:33:04.891801Z","shell.execute_reply":"2022-12-17T18:33:04.890491Z","shell.execute_reply.started":"2022-12-17T18:33:03.818703Z"},"trusted":true},"outputs":[],"source":["# !pip install GPUtil\n","\n","# from GPUtil import showUtilization as gpu_usage\n","# gpu_usage()    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-17T18:33:04.893834Z","iopub.status.busy":"2022-12-17T18:33:04.893449Z","iopub.status.idle":"2022-12-17T18:33:05.825842Z","shell.execute_reply":"2022-12-17T18:33:05.823621Z","shell.execute_reply.started":"2022-12-17T18:33:04.893795Z"},"trusted":true},"outputs":[],"source":["#end"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"82870c2f554ac463822076b994cf0f6148cb66eef85ce34abb8e9fcae1bddbbc"}}},"nbformat":4,"nbformat_minor":4}
