{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Video diffusion models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:15:36.639767Z","iopub.status.busy":"2023-01-19T18:15:36.639123Z","iopub.status.idle":"2023-01-19T18:16:33.258947Z","shell.execute_reply":"2023-01-19T18:16:33.257814Z","shell.execute_reply.started":"2023-01-19T18:15:36.639723Z"},"trusted":true},"outputs":[],"source":["!wget https://www.kaggleusercontent.com/kf/116808580/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..jsredvRKL5mb488KjnL_ag.Q6U8Eq6OWh4aijOVHH_YHitw8nG5nzKNuviS8PRAFG0HHi0fKQsU_CbQJc3rsT0w-u2eh_yG4hLX6qcIe7vEY3KmCSusbmxHFjjXah5Sl3CrU0pkDdH66MunAuEBExsPiITkJej3kjisldzwzKHbewtykhcj_sqclyXqLc4rATXfkNy6O6BhLwuiyzQrN98VlcMpUgBCDXLJvew38DZ8MtqA0GsKFjVfA_FZjxfVBetPeOGogWuraTBfNV4b5alWjSf0NekBqE2tB1MOQ2889KCUwgeo57zMEUeyoV45Id30BfHWuClTMpnLxg3xfzEh03OgKWvrLXCnm1Xt4lJG1v1jyZirKLNHE_WAjb5emN_Xu96iQxX920HeFfB4DddxzbBuptjdnZnp0Ln9wZW0UMPVUN_JvgMM4IcwqQ6yb1jq7FS1R7SkfUR7HjMBIF53wZFW7-SzAI3Auer3qxs_bkU6xZk_XQfHTdjeGiCOv6M_2BlTFW6kXmqR5erSUPi9-kqwcg7ZDwVK3Znu9SRoqSyzW1Ja0eSbpz7hFsW6W3YtpKpQivpqWPslGMCfRGMMWIa1XUCI6wrYFB-iXtmlvc8cVug4zI4XlgJDRdJwS225qy9n6TCRQtQ18S5dKNYTq3x-e1hzE35aAGik6Y_SNA.-wfOeyfpHsSR9AZlhtEuCw/checkpoint-e1_35-s1_600000-e2_36-s2_29695-1674197094.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:16:33.261408Z","iopub.status.busy":"2023-01-19T18:16:33.260996Z","iopub.status.idle":"2023-01-19T18:16:33.266923Z","shell.execute_reply":"2023-01-19T18:16:33.265993Z","shell.execute_reply.started":"2023-01-19T18:16:33.261366Z"},"trusted":true},"outputs":[],"source":["# Params\n","image_size = 128\n","frames = 12\n","process_batch_size = 128\n","\n","max_run_minutes = 12 * 60 - 10"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:16:33.270678Z","iopub.status.busy":"2023-01-19T18:16:33.269927Z","iopub.status.idle":"2023-01-19T18:16:33.419142Z","shell.execute_reply":"2023-01-19T18:16:33.418186Z","shell.execute_reply.started":"2023-01-19T18:16:33.270642Z"},"trusted":true},"outputs":[],"source":["import time\n","import os\n","start_time = time.time()"]},{"cell_type":"markdown","metadata":{},"source":["## Install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:16:33.423305Z","iopub.status.busy":"2023-01-19T18:16:33.422349Z","iopub.status.idle":"2023-01-19T18:16:55.862780Z","shell.execute_reply":"2023-01-19T18:16:55.861584Z","shell.execute_reply.started":"2023-01-19T18:16:33.423264Z"},"trusted":true},"outputs":[],"source":["!pip install imagen_pytorch==1.16.5 --no-cache-dir"]},{"cell_type":"markdown","metadata":{},"source":["## Utility functions to resize and crop GIFs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:16:55.865028Z","iopub.status.busy":"2023-01-19T18:16:55.864610Z","iopub.status.idle":"2023-01-19T18:16:55.884641Z","shell.execute_reply":"2023-01-19T18:16:55.883663Z","shell.execute_reply.started":"2023-01-19T18:16:55.864956Z"},"tags":[],"trusted":true},"outputs":[],"source":["# GIF pre-processing\n","\n","import numpy as np\n","from torchvision import transforms as T\n","from math import floor, fabs\n","from PIL import Image, ImageSequence\n","\n","\n","CHANNELS_TO_MODE = {\n","    1 : 'L',\n","    3 : 'RGB',\n","    4 : 'RGBA'\n","}\n","\n","def center_crop(img, new_width, new_height): \n","    width = img.size[0]\n","    height = img.size[1]\n","    left = int(np.ceil((width - new_width) / 2))\n","    right = width - int(np.floor((width - new_width) / 2))\n","    top = int(np.ceil((height - new_height) / 2))\n","    bottom = height - int(np.floor((height - new_height) / 2))\n","    return img.crop((left, top, right, bottom))\n","\n","def resize_crop_img(img, width, height):\n","    # width < height\n","    if( img.size[0] < img.size[1]):\n","        wpercent = (width/float(img.size[0]))\n","        hsize = int((float(img.size[1])*float(wpercent)))\n","        img = img.resize((width, hsize), Image.Resampling.LANCZOS)\n","    else: # width >= height\n","        hpercent = (height/float(img.size[1]))\n","        wsize = int((float(img.size[0])*float(hpercent)))\n","        img = img.resize((wsize, height), Image.Resampling.LANCZOS)\n","    img = center_crop(img, width, height)\n","    return img\n","\n","def transform_gif(img, new_width, new_height, frames, channels = 3):\n","    assert channels in CHANNELS_TO_MODE, f'channels {channels} invalid'\n","    mode = CHANNELS_TO_MODE[channels]\n","    gif_frames = img.n_frames\n","    for i in range(0, frames):\n","        img.seek(i % gif_frames)\n","        if img.size[0] != new_width or img.size[1] != new_height:\n","#             print(\"Resizing\")\n","            img_out = resize_crop_img(img, new_width, new_height)\n","        else:\n","            img_out = img\n","        yield img_out.convert(mode)\n","        \n","# tensor of shape (channels, frames, height, width) -> gif\n","def video_tensor_to_gif(tensor, path, fps = 10, loop = 0, optimize = True):\n","    print(\"Converting video tensors to GIF\")\n","    images = map(T.ToPILImage(), tensor.unbind(dim = 1))\n","    first_img, *rest_imgs = images\n","    print(1000/fps)\n","    first_img.save(path, save_all = True, append_images = rest_imgs, duration = int(1000/fps), loop = loop, optimize = optimize)\n","    print(\"Gif saved\")\n","    return images\n","\n","# gif -> (channels, frame, height, width) tensor\n","def gif_to_tensor(path, width = 256, height = 256, frames = 32, channels = 3, transform = T.ToTensor()):\n","    print(\"Converting GIF to video tensors\")\n","    img = Image.open(path)\n","    imgs = transform_gif(img, new_width = width, new_height = height, frames = frames, channels = channels)\n","    tensors = tuple(map(transform, imgs))\n","    return torch.stack(tensors, dim = 1)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Utility functions to process dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:16:55.886868Z","iopub.status.busy":"2023-01-19T18:16:55.886460Z","iopub.status.idle":"2023-01-19T18:16:55.898702Z","shell.execute_reply":"2023-01-19T18:16:55.897659Z","shell.execute_reply.started":"2023-01-19T18:16:55.886833Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import shutil\n","import urllib\n","import traceback\n","\n","from concurrent.futures import ThreadPoolExecutor, wait\n","import time\n","import threading\n","\n","dataset_size = 600000\n","train_data = \"../input/webvid-gif-600k/dataset_600K.tsv\"\n","data_dir = \"../input/webvid-gif-600k/data/\"\n","\n","current_step = 0\n","texts = []\n","list_videos = []\n","\n","\n","lock = threading.Lock()\n","executor = ThreadPoolExecutor(max_workers=15)\n","\n","def process_parallel(index, file_img, file_text):\n","    try:\n","        print(f\"Processing image {file_img}\")\n","        tensor = gif_to_tensor(data_dir + file_img, width = image_size, height = image_size, frames = frames)\n","        file_text = file_text[:-1] # Remove \\n\n","        with lock:\n","            list_videos.append(tensor)\n","            texts.append(file_text)\n","    except:\n","        traceback.print_exc()\n","    \n","def get_videos_parallel(index_start, index_end):\n","    global texts\n","    global list_videos\n","    \n","    texts = []\n","    list_videos = []\n","\n","    with open(train_data) as fp:\n","        futures = []\n","        for i, line in enumerate(fp):\n","            if i >= index_start and i< index_end :\n","                file_img, file_text = line.split(\"\\t\")\n","                future = executor.submit(process_parallel, i, file_img, file_text)\n","                futures.append(future)\n","            elif i > index_end:\n","                break\n","        wait(futures)\n","                \n","def get_next_videos():\n","    global current_step\n","    get_videos_parallel(current_step, current_step + process_batch_size)\n","    current_step += len(texts)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Utility functions to save and load checkpoints"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:16:58.734298Z","iopub.status.busy":"2023-01-19T18:16:58.733884Z","iopub.status.idle":"2023-01-19T18:16:58.752800Z","shell.execute_reply":"2023-01-19T18:16:58.751850Z","shell.execute_reply.started":"2023-01-19T18:16:58.734264Z"},"tags":[],"trusted":true},"outputs":[],"source":["import shutil\n","import torch\n","import time\n","import gc\n","import os\n","from imagen_pytorch import Unet3D, ElucidatedImagen, ImagenTrainer\n","from imagen_pytorch.data import Dataset\n","\n","checkpoints_path = \"./\"\n","checkpoint_path = \"\"\n","\n","# If there is a checkpoint these changes automatically at runtime\n","epoch_1 = 0\n","epoch_2 = 0\n","\n","step_1 = 0\n","step_2 = 0\n","\n","train_unet = 1\n","\n","def save_checkpoint(trainer: ImagenTrainer):\n","    global checkpoint_path\n","    global current_step\n","    global epoch_1\n","    global epoch_2\n","    global step_1\n","    global step_2\n","    print(\"Saving checkpoint\")\n","    current_time = int(time.time())\n","    if os.path.exists(checkpoint_path):\n","        os.remove(checkpoint_path)\n","    if train_unet == 1:\n","        step_1 = current_step\n","    else:\n","        step_2 = current_step\n","    checkpoint_path = os.path.join(checkpoints_path, f\"checkpoint-e1_{epoch_1}-s1_{step_1}-e2_{epoch_2}-s2_{step_2}-{current_time}.pt\")\n","    trainer.save(checkpoint_path)\n","\n","def update_config(checkpoint):\n","    global epoch_1\n","    global epoch_2\n","    global step_1\n","    global step_2\n","    global train_unet\n","    global current_step\n","    splitted = (checkpoint.replace(\".pt\", \"\").split(\"checkpoint-\")[1]).split(\"-\")\n","    epoch_1 = int(splitted[0].replace(\"e1_\", \"\"))\n","    step_1 = int(splitted[1].replace(\"s1_\", \"\"))\n","    epoch_2 = int(splitted[2].replace(\"e2_\", \"\"))\n","    step_2 = int(splitted[3].replace(\"s2_\", \"\"))\n","    print(\"Loaded configuration\")\n","    print(f\"Epoch unet 1: {epoch_1}\")\n","    print(f\"Steps unet 1: {step_1}\")\n","    print(f\"Epoch unet 2: {epoch_2}\")\n","    print(f\"Steps unet 2: {step_2}\")\n","    if epoch_2 >= epoch_1:\n","        train_unet = 1\n","        if step_1 >= dataset_size:\n","            current_step = 0\n","            epoch_1 += 1\n","        else:\n","            current_step = step_1\n","    else:\n","        train_unet = 2\n","        if step_2 >= dataset_size:\n","            current_step = 0\n","            epoch_2 += 1\n","        else:\n","            current_step = step_2\n","    print(f\"Unet {train_unet} selected\")\n","    print(f\"Current step: {current_step}\")\n","    \n","def config_new_epoch():\n","    global epoch_1\n","    global epoch_2\n","    global train_unet\n","    global current_step\n","    if train_unet == 1:\n","        epoch_1 += 1\n","    else:\n","        epoch_2 += 1\n","    current_step = 0\n","        \n","def load_checkpoint(trainer: ImagenTrainer):\n","    global checkpoint_path\n","    global epoch_1\n","    global epoch_2\n","    global step_1\n","    global step_2\n","    global train_unet\n","    global current_step\n","    print(\"Loading checkpoint\")\n","    timestamp = -1\n","    for file in os.listdir(checkpoints_path):\n","        if file.endswith('.pt'):\n","            new_timestamp = int((file.split(\"-\")[-1]).replace(\".pt\", \"\"))\n","            if new_timestamp > timestamp:\n","                checkpoint_path = os.path.join(checkpoints_path, file)\n","                timestamp = new_timestamp        \n","    if not os.path.exists(checkpoint_path):\n","        print(\"No checkpoint found -> starting from scratch\")\n","        epoch_1 = 0\n","        epoch_2 = 0\n","        step_1 = 0\n","        step_2 = 0\n","        current_step = 0\n","        train_unet = 1\n","        return None\n","    trainer.load(checkpoint_path)\n","    update_config(checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:16:58.754789Z","iopub.status.busy":"2023-01-19T18:16:58.754543Z","iopub.status.idle":"2023-01-19T18:17:05.682052Z","shell.execute_reply":"2023-01-19T18:17:05.681051Z","shell.execute_reply.started":"2023-01-19T18:16:58.754759Z"},"tags":[],"trusted":true},"outputs":[],"source":["unet1 = Unet3D(\n","    dim = 64,\n","    cond_dim = 128,\n","    dim_mults = (1, 2, 4, 8),\n","    num_resnet_blocks = 3,\n","    layer_attns = (False, True, True, True),\n","    layer_cross_attns = (False, True, True, True)\n",")\n","\n","unet2 = Unet3D(\n","    dim = 64,\n","    cond_dim = 128,\n","    dim_mults = (1, 2, 4, 8),\n","    num_resnet_blocks = (2, 4, 8, 8),\n","    layer_attns = (False, False, False, True),\n","    layer_cross_attns = (False, False, False, True)\n",")\n","\n","imagen = ElucidatedImagen(\n","    unets = (unet1, unet2),\n","    image_sizes = (16, 64),\n","    random_crop_sizes = (None, 16),\n","    num_sample_steps = 64,\n","    cond_drop_prob = 0.1,                       # gives the probability of dropout for classifier-free guidance.\n","    sigma_min = 0.002,                          # min noise level\n","    sigma_max = (80, 160),                      # max noise level, double the max noise level for upsampler\n","    sigma_data = 0.5,                           # standard deviation of data distribution\n","    rho = 7,                                    # controls the sampling schedule\n","    P_mean = -1.2,                              # mean of log-normal distribution from which noise is drawn for training\n","    P_std = 1.2,                                # standard deviation of log-normal distribution from which noise is drawn for training\n","    S_churn = 80,                               # parameters for stochastic sampling - depends on dataset, Table 5 in apper\n","    S_tmin = 0.05,\n","    S_tmax = 50,\n","    S_noise = 1.003,\n",").cuda()\n","\n","trainer = ImagenTrainer(imagen)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train Unet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T22:23:16.922890Z","iopub.status.busy":"2023-01-18T22:23:16.921900Z","iopub.status.idle":"2023-01-18T22:23:29.251487Z","shell.execute_reply":"2023-01-18T22:23:29.249884Z","shell.execute_reply.started":"2023-01-18T22:23:16.922846Z"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"source":["# Train \n","load_checkpoint(trainer)\n","while True:\n","    # if execution time is more than max_run_minutes stops\n","    if time.time() - start_time >= max_run_minutes * 60:\n","        break\n","    get_next_videos()\n","    if len(texts) == 0:\n","        save_checkpoint(trainer)\n","        config_new_epoch()\n","        get_next_videos()\n","#         break\n","    print(\"Generating tensor from videos\")\n","    videos = torch.stack(list_videos, dim = 0).cuda()\n","    print(f\"Training Unet {train_unet}\")\n","    trainer(videos, texts = texts, unet_number = train_unet, max_batch_size = 32)\n","    trainer.update(unet_number = train_unet)\n","    del videos\n","save_checkpoint(trainer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-19T18:17:05.686230Z","iopub.status.busy":"2023-01-19T18:17:05.685887Z","iopub.status.idle":"2023-01-19T18:19:07.069351Z","shell.execute_reply":"2023-01-19T18:19:07.068654Z","shell.execute_reply.started":"2023-01-19T18:17:05.686202Z"},"trusted":true},"outputs":[],"source":["texts_sample = ['A red cat']\n","load_checkpoint(trainer)\n","videos_out = trainer.sample(texts = texts_sample, video_frames = 24)\n","print(videos_out.shape)\n","video_tensor_to_gif(videos_out[0], f'out.gif', fps = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T19:16:58.301999Z","iopub.status.busy":"2023-01-17T19:16:58.301370Z","iopub.status.idle":"2023-01-17T19:16:58.306196Z","shell.execute_reply":"2023-01-17T19:16:58.305229Z","shell.execute_reply.started":"2023-01-17T19:16:58.301964Z"},"trusted":true},"outputs":[],"source":["# !pip install GPUtil\n","\n","# from GPUtil import showUtilization as gpu_usage\n","# gpu_usage()    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T19:16:58.310017Z","iopub.status.busy":"2023-01-17T19:16:58.309402Z","iopub.status.idle":"2023-01-17T19:16:58.315348Z","shell.execute_reply":"2023-01-17T19:16:58.314349Z","shell.execute_reply.started":"2023-01-17T19:16:58.309983Z"},"trusted":true},"outputs":[],"source":["#end"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
